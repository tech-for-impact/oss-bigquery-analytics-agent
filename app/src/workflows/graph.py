from typing import List, Union, Dict
from typing_extensions import TypedDict, Optional
from pathlib import Path # pathlib.Pathë¥¼ ì§ì ‘ ì‚¬ìš©í•˜ë„ë¡ ìˆ˜ì •
from functools import lru_cache

from langchain_core.output_parsers import StrOutputParser
from langchain_core.prompts import ChatPromptTemplate, load_prompt
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage
from langchain_core.runnables import RunnablePassthrough, RunnableLambda
from langgraph.graph import END, StateGraph

# ìƒˆ í”„ë¡œì íŠ¸ êµ¬ì¡°ì— ë§ê²Œ ê²½ë¡œ ìˆ˜ì •
from ..utils.llm.factory import LLMFactory # ìˆ˜ì •ëœ ê²½ë¡œ
# from .sql_chain import create_sql_chain # ìˆœí™˜ ì°¸ì¡° ë°©ì§€ë¥¼ ìœ„í•´ ì£¼ì„ ì²˜ë¦¬
from datetime import datetime

from ..utils.logger import logger # ìˆ˜ì •ëœ ê²½ë¡œ
from ..utils.date_utils import format_date, check_query_date # ìˆ˜ì •ëœ ê²½ë¡œ

# ìƒˆ í”„ë¡œì íŠ¸ êµ¬ì¡°ì— ë§ê²Œ ê²½ë¡œ ìˆ˜ì •
PROMPT_DIR = Path(__file__).parent.parent.parent / "prompts" # graph.py ìœ„ì¹˜ì—ì„œ app/prompts ë¥¼ ìƒëŒ€ê²½ë¡œë¡œ ì§€ì •
llm = LLMFactory.create_from_settings(temperature=0.0)

class GraphState(TypedDict):
    messages: List[Union[HumanMessage, AIMessage, SystemMessage]]
    org_table_name: Optional[str]
    state: Optional[str]
    SQLquery: Optional[str]
    chat_id: Optional[str] # chat_idëŠ” report ìƒì„± ì‹œ ì‚¬ìš©ë˜ì—ˆìœ¼ë‚˜, ë‹¤ë¥¸ ìš©ë„ë¡œ ì‚¬ìš©ë  ìˆ˜ ìˆìœ¼ë¯€ë¡œ ìœ ì§€
    answer: Optional[str] # SQL ì¿¼ë¦¬ ë˜ëŠ” ìµœì¢… ë‹µë³€ì„ ì €ì¥

def get_full_input(state: GraphState) -> str:
    messages_contents = [f"{'HumanMessage' if m.type == 'human' else 'AIMessage'}: {m.content}" for m in state["messages"]]
    return "\\n".join(messages_contents)

def get_latest_input(state: GraphState) -> str:
    if len(state["messages"]) > 0 and state["messages"][-1].type == "human":
        return state["messages"][-1].content
    return ""

def categorized(state: GraphState) -> GraphState:
    state["state"] = "categorized"
    state["answer"] = ""
    state["SQLquery"] = ""
    logger.info(f"MessageHistory : {state['messages']}")
    user_prompt = load_prompt(PROMPT_DIR / "categorized.yaml", encoding="utf-8")
    prompt_template = ChatPromptTemplate.from_messages([
        ("placeholder", "{messages}"),
        ("human", user_prompt.format(input="{input}"))
    ])
    chain = prompt_template | llm | StrOutputParser()
    try:
        response = chain.invoke({
            "messages": state["messages"][:-1] if len(state["messages"]) > 1 else [],
            "input": state["messages"][-1].content
        })
        result = response.strip()
        classification_map = {
            "block": ("block", "blockìœ¼ë¡œ ë¶„ë¥˜"),
            "out_of_scope": ("out_of_scope", "out_of_scope ë¡œ ë¶„ë¥˜"),
            "SQLquery": ("SQLquery", "ì¿¼ë¦¬ë¬¸ ìƒì„±ìœ¼ë¡œ ë¶„ë¥˜"),
        }
        logger.info(f"categorized : {result}")
        if result in classification_map:
            state["state"], state["answer"] = classification_map[result]
        else:
            state["state"] = "roll_base_answer"
            state["answer"] = f"ì•Œ ìˆ˜ ì—†ëŠ” ë¶„ë¥˜ ê²°ê³¼ {result}"
    except Exception as e:
        print(f"Classification error: {str(e)}")
        state["state"] = "roll_base_answer"
        state["answer"] = "ì‘ë‹µì„ ìƒì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    return state

def roll_base_answer(state: GraphState) -> GraphState:
    """
    block, out_of_scope, ê¸°íƒ€(unknown) ìƒí™©ì—ì„œ ì•ˆë‚´ ë©”ì‹œì§€ ë°˜í™˜.
    """
    if state["state"] == "block":
        state["answer"] = "ğŸš« ì•—! ì„œë¹„ìŠ¤ ì´ìš© ì¤‘ ë¶€ì ì ˆí•œ í‘œí˜„ì´ ê°ì§€ë˜ì—ˆì–´ìš”. ë°ì´í„°ë¥¼ ë¶„ì„í•˜ëŠ” ì§ˆë¬¸ì„ ì…ë ¥í•´ ì£¼ì‹œë©´, ë” ì¢‹ì€ ë‹µë³€ì„ ë“œë¦´ê²Œìš”!"
    elif state["state"] == "out_of_scope":
        state["answer"] = "ğŸ˜… ì œê°€ ì•„ëŠ” ë¶„ì•¼ê°€ ì•„ë‹ˆì—ìš”! ì €ëŠ” í›„ì› ë°ì´í„° ë¶„ì„ ì „ë¬¸ê°€ëë‹ˆë‹¤!\nì˜ˆ: 'ì§€ë‚œì£¼ youtube / video ì±„ë„ì˜ ë°©ë¬¸ì ìˆ˜ ì•Œë ¤ì¤˜' ê°™ì€ ì§ˆë¬¸ì„ í•´ë³´ì„¸ìš”!"
    elif state["state"] == "out_of_date":
        state["answer"] = "ğŸ—“ï¸ ë°ì´í„° ì¡°íšŒëŠ” 2024.01.01ë¶€í„° ê°€ëŠ¥í•©ë‹ˆë‹¤."
    else:
        state["answer"] = "ì•—! ìƒê°í•˜ëŠ” ë„ì¤‘ì— ë¬¸ì œê°€ ìƒê²¼ì–´ìš”. ë°ì´í„° ë¶„ì„ì„ ìš”êµ¬í•˜ëŠ” ì§ˆë¬¸ìœ¼ë¡œ ìš”ì²­í•´ì£¼ì‹œë©´ ì˜ ìƒê°í•´ì„œ ë‹µë³€ ë“œë¦´ê²Œìš”!"
    
    logger.info(f"roll_base_answer : answer=\"{state['answer']}\", messages=\"{state['messages']}\"")
    return state

def missing_data_answer(state: GraphState) -> GraphState:
    state["state"] = "missing_data_answer"
    prompt = load_prompt(PROMPT_DIR / "missing_data.yaml", encoding="utf-8")
    chain = prompt | llm | StrOutputParser()
    response = chain.invoke({
        "input": state["messages"][-1].content,
        "messages": state["messages"][:-1] if len(state["messages"]) > 1 else []
    })
    state["answer"] = response
    logger.info(f"missing_data_answer : {state['answer']}")
    return state

def judged_sql_query(state: GraphState) -> GraphState:
    state["state"] = "judged_sql_query"
    prompt = load_prompt(PROMPT_DIR / "judge_sql_or_end.yaml", encoding="utf-8")
    chat_prompt = ChatPromptTemplate.from_messages([
        ("placeholder", "{messages}"),
        ("human", prompt.format(input="{input}"))
    ])
    chain = chat_prompt | llm | StrOutputParser()
    response = chain.invoke({
        "messages": state["messages"][:-1] if len(state["messages"]) > 1 else [],
        "input": state["messages"][-1].content
    })
    answer = response.strip().lower()
    if answer == "true":
        state["answer"] = "True"
    else:
        state["answer"] = "False"
    logger.info(f"judged_sql_query : {answer}")
    return state

def transfer_date(state: GraphState) -> GraphState:
    state["state"] = "transfer_date"
    current_date = format_date(datetime.now())
    user_query = get_latest_input(state)
    is_valid_date = check_query_date(user_query)
    if not is_valid_date:
        state["state"] = "out_of_date"
        return state
    prompt_template = load_prompt(PROMPT_DIR / "rewrite_question.yaml", encoding="utf-8")
    chain = prompt_template | llm | StrOutputParser()
    response = chain.invoke({
        "input": get_latest_input(state),
        "current_date": current_date,
        "messages": state["messages"][:-1] if len(state["messages"]) > 1 else []
    })
    state["messages"][-1].content = response
    is_valid_date_after = check_query_date(response)
    if not is_valid_date_after:
        state["state"] = "out_of_date"
        return state
    logger.info(f"transfer_date : {response}")
    return state

def transfer_TextToSQL(state: GraphState) -> GraphState:
    state["state"] = "transfer_TextToSQL"
    
    llm = LLMFactory.create_from_settings(temperature=0.0)

    # í”„ë¡¬í”„íŠ¸ ë¡œë“œ
    system_prompt = load_prompt(PROMPT_DIR / "text2sql_system.yaml", encoding="utf-8").template
    user_prompt = load_prompt(PROMPT_DIR / "text2sql_user.yaml", encoding="utf-8").template

    chain = (
        ChatPromptTemplate.from_messages([
            ("system", system_prompt),
            ("placeholder", "{messages}"),
            ("human", user_prompt)])
        | llm
        | StrOutputParser()
    )
    
    # TODO: schemaì™€ examplesëŠ” ì‹¤ì œ ê°’ìœ¼ë¡œ ëŒ€ì²´í•´ì•¼ í•©ë‹ˆë‹¤.
    schema_placeholder = "column_name:type, column_name2:type"  # ì„ì‹œ ìŠ¤í‚¤ë§ˆ
    examples_placeholder = "Question: ì˜ˆì‹œ ì§ˆë¬¸\\nSQL: SELECT ì˜ˆì‹œ_ì»¬ëŸ¼ FROM ì˜ˆì‹œ_í…Œì´ë¸”" # ì„ì‹œ ì˜ˆì œ

    sql_query_input = {
        "messages": state["messages"][:-1] if len(state["messages"]) > 1 else [],
        "input": state["messages"][-1].content if state["messages"][-1].type == "human" else "",
        "table_name": state["org_table_name"],
        "schema": schema_placeholder, # ì„ì‹œ ìŠ¤í‚¤ë§ˆ ì „ë‹¬
        "examples": examples_placeholder # ì„ì‹œ ì˜ˆì œ ì „ë‹¬
    }
    
    generated_sql = chain.invoke(sql_query_input).replace("medium_sample", state["org_table_name"])
    state["SQLquery"] = generated_sql # ìƒì„±ëœ SQLì„ SQLquery í•„ë“œì— ì €ì¥
    
    if state["org_table_name"] != "medium_sample":
        state["SQLquery"] = state["SQLquery"].replace("source_report", "SOURCE_REPORT").replace("page_report", "PAGE_REPORT").replace("event_report", "EVENT_REPORT")
    
    state["answer"] = state["SQLquery"] # ìƒì„±ëœ SQL ì¿¼ë¦¬ë¥¼ answer í•„ë“œì—ë„ ì €ì¥
    logger.info(f"transfer_TextToSQL: Generated SQL: {state['SQLquery']}") # ë¡œê·¸ ì¶”ê°€

    return state

@lru_cache(maxsize=2)
def create_graph_chain():
    workflow = StateGraph(GraphState)
    workflow.add_node("categorized", categorized)
    workflow.add_node("judged_sql_query", judged_sql_query)
    workflow.add_node("roll_base_answer", roll_base_answer)
    workflow.add_node("transfer_date", transfer_date)
    workflow.add_node("transfer_TextToSQL", transfer_TextToSQL)
    workflow.add_node("missing_data_answer", missing_data_answer)

    workflow.add_conditional_edges(
        "categorized",
        lambda state: state["state"],
        {
            "SQLquery": "transfer_date",
            "block": "roll_base_answer",
            "out_of_scope": "roll_base_answer",
            "roll_base_answer": "roll_base_answer" # ì•Œ ìˆ˜ ì—†ëŠ” ë¶„ë¥˜ ê²°ê³¼ ì‹œ
        }
    )
    workflow.add_conditional_edges(
        "transfer_date",
        lambda state: state["state"],
        {
            "out_of_date": "roll_base_answer", # ë‚ ì§œê°€ ìœ íš¨í•˜ì§€ ì•Šìœ¼ë©´ ë¡¤ë² ì´ìŠ¤ ë‹µë³€
            "transfer_date": "judged_sql_query" # ë‚ ì§œ ë³€í™˜ ì„±ê³µ ì‹œ SQL íŒë‹¨ìœ¼ë¡œ
        }
    )
    workflow.add_conditional_edges(
        "judged_sql_query",
        lambda state: state["answer"],
        {
            "True": "transfer_TextToSQL",
            "False": "missing_data_answer"
        }
    )
    workflow.set_entry_point("categorized")
    workflow.add_edge("transfer_TextToSQL", END)
    workflow.add_edge("missing_data_answer", END)
    workflow.add_edge("roll_base_answer", END)
    
    app = workflow.compile()
    return app

# ì‚¬ìš© ì˜ˆì‹œ (í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•´ ì¶”ê°€, ì‹¤ì œ ì‚¬ìš© ì‹œì—ëŠ” ì œê±°)
if __name__ == '__main__':
    # ì˜ˆì‹œ: ì‚¬ìš©ìê°€ "ì§€ë‚œì£¼ youtube ì±„ë„ ë°©ë¬¸ì ìˆ˜ ì•Œë ¤ì¤˜" ë¼ê³  ì§ˆë¬¸
    initial_state = GraphState(
        messages=[HumanMessage(content="ì§€ë‚œì£¼ youtube ì±„ë„ ë°©ë¬¸ì ìˆ˜ ì•Œë ¤ì¤˜")],
        org_table_name="medium_sample", # ì˜ˆì‹œ í…Œì´ë¸” ì´ë¦„
        state=None,
        SQLquery=None,
        chat_id="test_chat_id", # ì˜ˆì‹œ ì±„íŒ… ID
        answer=None
    )

    # ê·¸ë˜í”„ ì²´ì¸ ìƒì„± (ë²„ì „ ëª…ì‹œ ì—†ì´)
    graph_app = create_graph_chain()

    # ì‹¤í–‰
    final_state = graph_app.invoke(initial_state)
    print(f"ìµœì¢… ìƒíƒœ: {final_state}")
    print(f"ìµœì¢… ë‹µë³€: {final_state['answer']}")
    if final_state['SQLquery']:
        print(f"ìƒì„±ëœ SQL ì¿¼ë¦¬: {final_state['SQLquery']}") 